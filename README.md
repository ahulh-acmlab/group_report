# 组会报告记录

## 2021年4月21日

| 论文     | EfficientNetV2: Smaller Models and Faster Training           |
| -------- | ------------------------------------------------------------ |
| 发表时间 | 2021年3月                                                    |
| 作者     | Mingxing Tan , Quoc V. Le                                    |
| 来源     | Google brain                                                 |
| 主要内容 | 本文介绍了EfficientNetV2，这是一种用于图像识别的更小，更快的神经网络新系列。Efficient-NetV2通过具有训练意识的**NAS和模型扩展**进行了优化，其性能大大优于以前的模型，同时在参数上更快速，更高效。 为了进一步加快训练速度，我们提出了一种改进的**渐进式学习**方法，该方法可以在训练过程中共同**增加图像大小和正则化**。 |
| 实验结果 | 大量实验表明，我们的EfficientNetV2在Ima-geNet和CIFAR /鲜花/汽车上均取得了出色的成绩。 与EfficientNet和更近期的作品相比，我们的EfficientNetV2的**训练速度提高了11倍，而小了6.8倍**. |
| paper    | [EfficientNetV2.pdf](https://github.com/ahulh-acmlab/group_report/blob/main/2021-4-21/EfficientNetV2.pdf) |
| code     | <https://github.com/google/automl/>(efficientv2的代码尚未)   |
| ppt      | [EfficientNetV2.pptx](https://github.com/ahulh-acmlab/group_report/blob/main/2021-4-21/EfficientNetV2.pptx) |
| 报告人   | [吴昌广](https://github.com/PiKaChu-wcg)                     |



